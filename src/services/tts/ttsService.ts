/**
 * TTS (Text-to-Speech) æœåŠ¡
 * æ”¯æŒ OpenAI å’Œ Gemini TTS API è¿›è¡Œè¯­éŸ³åˆæˆ
 */

import type { TTSVoice, TTSModel, GeminiTTSModel } from '@/types/tts';
import { SecureStorage, STORAGE_KEYS } from '@/services/storage/secureStorage';
import type { TranslateConfig } from '@/types';

export interface TTSConfig {
  voice?: TTSVoice;
  model?: TTSModel;
  speed?: number; // 0.25 - 4.0
  useServerSide?: boolean;
  // OpenAI å‚æ•°
  apiKey?: string;
  baseURL?: string;
  voiceInstructions?: string; // ä»…é€‚ç”¨äº gpt-4o-mini-tts æ¨¡å‹
  // Gemini å‚æ•°
  geminiApiKey?: string;
  geminiBaseURL?: string;
  language?: string;
  format?: 'mp3' | 'wav';
  stylePrompt?: string; // Geminié£æ ¼æ§åˆ¶
}

export interface TTSRequest {
  text: string;
  voice?: TTSVoice;
  model?: TTSModel;
  speed?: number;
  voiceInstructions?: string;
  language?: string;
  format?: 'mp3' | 'wav';
  stylePrompt?: string;
}

export interface TTSResponse {
  success: boolean;
  audioUrl?: string;
  error?: string;
  duration?: number;
}

// æ£€æµ‹TTSæä¾›å•†
function detectTTSProvider(model: TTSModel): 'openai' | 'gemini' {
  const geminiModels: GeminiTTSModel[] = ['gemini-2.5-flash-preview-tts', 'gemini-2.5-pro-preview-tts'];
  return geminiModels.includes(model as GeminiTTSModel) ? 'gemini' : 'openai';
}

class TTSService {
  private defaultConfig: TTSConfig = {
    voice: 'alloy',
    model: 'tts-1',
    speed: 1.0,
    useServerSide: false,
    language: 'zh-CN',
    format: 'mp3'
  };

  private audioCache = new Map<string, string>();
  private currentAudio: HTMLAudioElement | null = null;

  constructor(config?: TTSConfig) {
    if (config) {
      this.defaultConfig = { ...this.defaultConfig, ...config };
    }
  }

  /**
   * è¯­éŸ³åˆæˆ
   */
  async generateSpeech(request: TTSRequest): Promise<TTSResponse> {
    const startTime = Date.now();
    
    try {
      // åˆå¹¶é…ç½®
      const config: TTSConfig = {
        ...this.defaultConfig,
        voice: request.voice || this.defaultConfig.voice,
        model: request.model || this.defaultConfig.model,
        speed: request.speed || this.defaultConfig.speed,
        voiceInstructions: request.voiceInstructions || this.defaultConfig.voiceInstructions,
        language: request.language || this.defaultConfig.language,
        format: request.format || this.defaultConfig.format,
        stylePrompt: request.stylePrompt || this.defaultConfig.stylePrompt,
      };

      console.log('TTS è¯·æ±‚é…ç½®:', {
        voice: config.voice,
        model: config.model,
        speed: config.speed,
        provider: detectTTSProvider(config.model!),
        useServerSide: config.useServerSide,
        textLength: request.text.length,
        language: config.language,
        format: config.format,
        hasStylePrompt: !!config.stylePrompt
      });

      // æ£€æŸ¥ç¼“å­˜
      const cacheKey = `${request.text}-${config.voice}-${config.model}-${config.speed}`;
      if (this.audioCache.has(cacheKey)) {
        console.log('ä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘');
        return {
          success: true,
          audioUrl: this.audioCache.get(cacheKey)!,
          duration: Date.now() - startTime,
        };
      }

      // ä»å­˜å‚¨ä¸­è·å–APIå¯†é’¥
      const savedConfig = SecureStorage.get<TranslateConfig>(STORAGE_KEYS.TRANSLATE_CONFIG);
      const provider = detectTTSProvider(config.model!);
      
      let apiConfig: {
        apiKey?: string;
        baseURL?: string;
        geminiApiKey?: string;
        geminiBaseURL?: string;
      } = {};

      if (provider === 'openai') {
        apiConfig = {
          apiKey: config.apiKey || savedConfig?.apiKey,
          baseURL: config.baseURL || savedConfig?.baseURL,
        };
      } else if (provider === 'gemini') {
        apiConfig = {
          geminiApiKey: config.geminiApiKey || savedConfig?.geminiApiKey,
          geminiBaseURL: config.geminiBaseURL || savedConfig?.geminiBaseURL,
        };
      }

      console.log('TTS API é…ç½®:', {
        provider,
        hasApiKey: !!(apiConfig.apiKey || apiConfig.geminiApiKey),
        baseURL: apiConfig.baseURL || apiConfig.geminiBaseURL
      });

      // ç¬¬ä¸€æ­¥ï¼šPOST è¯·æ±‚å­˜å‚¨é…ç½®ï¼Œè·å– UUID
      const requestBody = {
        text: request.text,
        voice: config.voice,
        model: config.model,
        speed: config.speed,
        voiceInstructions: config.voiceInstructions,
        language: config.language,
        format: config.format,
        stylePrompt: config.stylePrompt,
        userConfig: apiConfig,
      };

      console.log('å‘é€TTSè¯·æ±‚:', {
        ...requestBody,
        text: requestBody.text.substring(0, 50) + (requestBody.text.length > 50 ? '...' : ''),
        userConfig: {
          hasApiKey: !!(apiConfig.apiKey || apiConfig.geminiApiKey),
          baseURL: apiConfig.baseURL || apiConfig.geminiBaseURL
        }
      });

      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.error || `HTTP ${response.status}`);
      }

      const result = await response.json();
      
      if (!result.success || !result.audioUrl) {
        throw new Error('Failed to get TTS URL');
      }

      // ç¬¬äºŒæ­¥ï¼šä½¿ç”¨è¿”å›çš„ audioUrlï¼ˆåŒ…å« UUIDï¼‰ä½œä¸ºéŸ³é¢‘æº
      const audioUrl = result.audioUrl; // æ ¼å¼: /api/tts/{uuid}

      // ç¼“å­˜éŸ³é¢‘ URL
      this.audioCache.set(cacheKey, audioUrl);

      return {
        success: true,
        audioUrl,
        duration: Date.now() - startTime,
      };

    } catch (error) {
      console.error('TTS generation error:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        duration: Date.now() - startTime,
      };
    }
  }

  /**
   * æ’­æ”¾è¯­éŸ³
   */
  async playAudio(audioUrl: string): Promise<void> {
    console.log('ğŸµ å¼€å§‹æ’­æ”¾éŸ³é¢‘:', audioUrl);
    
    return new Promise((resolve, reject) => {
      // åœæ­¢å½“å‰æ’­æ”¾
      this.stopAudio();

      // åˆ›å»ºæ–°çš„éŸ³é¢‘å…ƒç´ 
      this.currentAudio = new Audio();
      
      // è®¾ç½®éŸ³é¢‘å±æ€§
      this.currentAudio.preload = 'auto';
      this.currentAudio.volume = 1.0;
      this.currentAudio.crossOrigin = 'anonymous';
      
      // æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
      this.currentAudio.onloadstart = () => {
        console.log('ğŸµ éŸ³é¢‘å¼€å§‹åŠ è½½');
      };

      this.currentAudio.onloadeddata = () => {
        console.log('ğŸµ éŸ³é¢‘æ•°æ®åŠ è½½å®Œæˆ');
      };

      this.currentAudio.oncanplay = () => {
        console.log('ğŸµ éŸ³é¢‘å¯ä»¥å¼€å§‹æ’­æ”¾');
      };

      this.currentAudio.oncanplaythrough = () => {
        console.log('ğŸµ éŸ³é¢‘å¯ä»¥æµç•…æ’­æ”¾');
      };

      this.currentAudio.onplay = () => {
        console.log('ğŸµ éŸ³é¢‘å¼€å§‹æ’­æ”¾');
      };

      this.currentAudio.onplaying = () => {
        console.log('ğŸµ éŸ³é¢‘æ­£åœ¨æ’­æ”¾');
      };

      this.currentAudio.onpause = () => {
        console.log('ğŸµ éŸ³é¢‘æš‚åœ');
      };
      
      // äº‹ä»¶ç›‘å¬å™¨
      this.currentAudio.onended = () => {
        console.log('ğŸµ éŸ³é¢‘æ’­æ”¾å®Œæˆ');
        this.currentAudio = null;
        resolve();
      };

      this.currentAudio.onerror = () => {
        const audio = this.currentAudio;
        console.error('âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯');
        
        if (audio && audio.error) {
          let errorMsg = 'Unknown audio error';
          switch(audio.error.code) {
            case audio.error.MEDIA_ERR_ABORTED:
              errorMsg = 'Audio loading was aborted';
              break;
            case audio.error.MEDIA_ERR_NETWORK:
              errorMsg = 'Network error while loading audio';
              break;
            case audio.error.MEDIA_ERR_DECODE:
              errorMsg = 'Audio decoding error - éŸ³é¢‘æ ¼å¼å¯èƒ½ä¸æ”¯æŒ';
              break;
            case audio.error.MEDIA_ERR_SRC_NOT_SUPPORTED:
              errorMsg = 'Audio source not supported - éŸ³é¢‘æºä¸æ”¯æŒ';
              break;
          }
          console.error('éŸ³é¢‘é”™è¯¯è¯¦æƒ…:', {
            code: audio.error.code,
            message: errorMsg,
            audioSrc: audio.src
          });
          this.currentAudio = null;
          reject(new Error(errorMsg));
        } else {
          console.error('æœªçŸ¥éŸ³é¢‘æ’­æ”¾é”™è¯¯');
          this.currentAudio = null;
          reject(new Error('Audio playback failed'));
        }
      };

      // è®¾ç½®éŸ³é¢‘æºå¹¶å¼€å§‹æ’­æ”¾
      console.log('ğŸµ è®¾ç½®éŸ³é¢‘æº:', audioUrl);
      this.currentAudio.src = audioUrl;
      
      // å°è¯•æ’­æ”¾
      this.currentAudio.play()
        .then(() => {
          console.log('ğŸµ æ’­æ”¾è¯·æ±‚æˆåŠŸ');
        })
        .catch((error) => {
          console.error('âŒ æ’­æ”¾å¤±è´¥:', error);
          // ç‰¹æ®Šå¤„ç†è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢çš„æƒ…å†µ
          if (error.name === 'NotAllowedError') {
            console.warn('âš ï¸ è‡ªåŠ¨æ’­æ”¾è¢«æµè§ˆå™¨é˜»æ­¢ï¼Œéœ€è¦ç”¨æˆ·äº¤äº’');
            // è¿™ç§æƒ…å†µä¸‹ä¸ç®—é”™è¯¯ï¼Œåªæ˜¯éœ€è¦ç”¨æˆ·æ‰‹åŠ¨æ“ä½œ
          } else {
            console.error('æ’­æ”¾é”™è¯¯è¯¦æƒ…:', {
              name: error.name,
              message: error.message,
              audioSrc: this.currentAudio?.src
            });
            this.currentAudio = null;
            reject(new Error(`Audio playback failed: ${error.message}`));
          }
        });
    });
  }

  /**
   * åœæ­¢æ’­æ”¾
   */
  stopAudio(): void {
    if (this.currentAudio) {
      this.currentAudio.pause();
      this.currentAudio.currentTime = 0;
      this.currentAudio = null;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
   */
  isPlaying(): boolean {
    return Boolean(this.currentAudio && !this.currentAudio.paused);
  }

  /**
   * æ¸…ç†ç¼“å­˜
   */
  clearCache(): void {
    // é‡Šæ”¾æ‰€æœ‰ Blob URL
    for (const url of this.audioCache.values()) {
      URL.revokeObjectURL(url);
    }
    this.audioCache.clear();
  }

  /**
   * è·å–ç¼“å­˜é”®
   */
  private getCacheKey(text: string, config: TTSConfig): string {
    return `${text}-${config.voice}-${config.model}-${config.speed}`;
  }

  /**
   * è¯­éŸ³åˆæˆå¹¶æ’­æ”¾ï¼ˆä¸€æ­¥å®Œæˆï¼‰
   */
  async speakText(request: TTSRequest): Promise<TTSResponse> {
    const result = await this.generateSpeech(request);
    
    if (result.success && result.audioUrl) {
      try {
        await this.playAudio(result.audioUrl);
      } catch {
        return {
          ...result,
          success: false,
          error: 'Audio playback failed',
        };
      }
    }

    return result;
  }
}

// å…¨å±€ TTS æœåŠ¡å®ä¾‹
let ttsServiceInstance: TTSService | null = null;

export const getTTSService = (): TTSService => {
  if (!ttsServiceInstance) {
    ttsServiceInstance = new TTSService();
  }
  return ttsServiceInstance;
};

export const initTTSService = (config?: TTSConfig): TTSService => {
  const service = getTTSService();
  if (config) {
    service['defaultConfig'] = { ...service['defaultConfig'], ...config };
  }
  return service;
};

// ä¾¿æ·å‡½æ•°
export const speakText = async (text: string, config?: TTSConfig): Promise<TTSResponse> => {
  const service = getTTSService();
  const request: TTSRequest = {
    text,
    voice: config?.voice,
    model: config?.model,
    speed: config?.speed,
    voiceInstructions: config?.voiceInstructions,
    language: config?.language,
    format: config?.format,
    stylePrompt: config?.stylePrompt,
  };
  return service.speakText(request);
};

export const stopSpeaking = (): void => {
  const service = getTTSService();
  service.stopAudio();
};

export const isSpeaking = (): boolean => {
  const service = getTTSService();
  return service.isPlaying();
}; 